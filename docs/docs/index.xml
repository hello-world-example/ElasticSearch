<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on ElasticSearch</title>
    <link>https://hello-world-example.github.io/ElasticSearch/docs/</link>
    <description>Recent content in Docs on ElasticSearch</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://hello-world-example.github.io/ElasticSearch/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/analyzer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/analyzer/</guid>
      <description>Analyzer 分析器 Read More  Elasticsearch - 指定分析器  </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/core-concept/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/core-concept/</guid>
      <description>基础概念 Lucene 词汇表  文档 document ：索引和搜索时使用的主要数据载体，包含一个或多个存有数据的字段 字段 field ：文档的一部分，包含名称和值两部分 词 term： 一个搜索单元，表示文本中的一个词 标记 token ：在字段文本中出现的词，由这个词的文本、开始和结束偏移量以及类 型组成 倒排索引 inverted index 索引分为多个的段segment。一个段写入磁盘后就不能再更新，被删除文档的信息存储在一个单独的文件中，多个段可以通过段合并segments merge合并在一起，合并时不再需要的信息将被删除 分析器 由一个分词器 tokenizer和零个或多个标记过滤器 token filter组成，也可以有零个或多个字符映射器character mapper 评分scoring  ElasticSearch 核心概念 数据架构   **索引（index）**是Elasticsearch对逻辑数据的逻辑存储，可以把索引看成关系型数据库的表
  存储在Elasticsearch中的主要实体叫文档（document），用关系型数据库来类比的话，一个文档相当于数据库表中的一行记录
  文档由多个字段组成，每个字段可能多次出现在一个文档里，这样的字段叫多值字段（multivalued）。与关系型数据库不同，文档不需要有固定的结构，每个文档可以有不同的字段
  在Elasticsearch中，一个索引对象可以存储很多不同用途的对象，文档类型让我们轻易地区分单个索引中的不同对象。但是有一个限制，不同的文档类型不能为相同的属性设置不同的类型
  文档中的每个字段都必须根据不同类型做相应的分析， Elasticsearch在映射中存储有关字段的信息，可理解为字段类型
   数据存储在一个或多个索引上
索引包含各种类型的文档
文档有很多字段
映射定义了如何对待这些字段
 集群概念  Elasticsearch 可以运行在许多互相合作的服务器上，这些服务器称为集群（cluster），形成集群的每个服务器称为节点（node） 索引切分成较小的**分片（shard）**放在不同的服务器上，其中每个分片都是一个独立的Apache Lucene索引，多个分片可以加快索引和查询速度。当查询的索引分布在多个分片上时， ES 会把查询发送给每个相关的分片，并将结果合并在一起，而应用程序并不知道分片的存在。 **副本（replica）**只是一个分片的精确复制，每个分片可以有零个或多个副本 副本分片（replica shard） 可从 主分片（primary shard） 复制数据，在主分片丢失时，集群会将副本提升为新的主分片  Read More  Basic Concepts 官方文档  </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/dump/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/dump/</guid>
      <description>导入导出 elasticsearch-dump  详见官方文档： https://github.com/taskrabbit/elasticsearch-dump
 安装 $ mkdir /opt/websuite/elasticdump $ cd /opt/websuite/elasticdump # 本地安装 $ npm install elasticdump # 查看帮助 $ ./node_modules/elasticdump/bin/elasticdump --help 常用命令 # # 导出 # $ /opt/websuite/elasticdump/node_modules/elasticdump/bin/elasticdump \  --input=http://172.16.2.164:9200/dev_carmodel \  --output=/tmp/es/dev_carmodel_mapping.json \  --type=mapping $ /opt/websuite/elasticdump/node_modules/elasticdump/bin/elasticdump \  --input=http://172.16.2.164:9200/dev_carmodel \  --output=/tmp/es/dev_carmodel_data.json \  --type=data # # 导入 # $ /opt/websuite/elasticdump/node_modules/elasticdump/bin/elasticdump \  --input=/tmp/es/dev_carmodel_data.json \  --output=http://172.16.2.164:9200/dev_carmodel_dump \  --type=data # # 复制数据 # $ /opt/websuite/elasticdump/node_modules/elasticdump/bin/elasticdump \  --input=http://172.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/ik-plugin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/ik-plugin/</guid>
      <description>IK 中文分词 安装 # https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip $ Version=$(curl -s http://localhost:9200 | grep number | awk -F &amp;#39;&amp;#34;&amp;#39; &amp;#39;{print $4}&amp;#39;) $ ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v${Version}/elasticsearch-analysis-ik-${Version}.zip -&amp;gt; Downloading https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.6.12/elasticsearch-analysis-ik-5.6.12.zip [===========================&amp;gt; ] 56% 安装后启动报错问题 报错内容 [2019-02-26T07:19:11,994][INFO ][o.e.n.Node ] [KpRS12p] started [2019-02-26T07:19:12,421][INFO ][o.w.a.d.Monitor ] try load config from /usr/share/elasticsearch/config/analysis-ik/IKAnalyzer.cfg.xml [2019-02-26T07:19:12,425][INFO ][o.w.a.d.Monitor ] try load config from /usr/share/elasticsearch/plugins/analysis-ik/config/IKAnalyzer.cfg.xml [2019-02-26T07:19:12,426][ERROR][o.w.a.d.Monitor ] ik-analyzer java.io.FileNotFoundException: /usr/share/elasticsearch/config/analysis-ik/IKAnalyzer.cfg.xml (No such file or directory) at java.io.FileInputStream.open0(Native Method) ~[?:1.8.0_181] at java.io.FileInputStream.open(FileInputStream.java:195) ~[?:1.8.0_181] at java.io.FileInputStream.&amp;lt;init&amp;gt;(FileInputStream.java:138) ~[?</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/java-client/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/java-client/</guid>
      <description>Java Client 简介   elasticsearch-rest-client 使用 9200 HTTP 协议进行通讯，上手简单，是低阶 API
 org.apache.httpcomponents:httpasyncclient org.apache.httpcomponents:httpcore-nio org.apache.httpcomponents:httpclient org.apache.httpcomponents:httpcore commons-codec:commons-codec commons-logging:commons-logging    elasticsearch-rest-high-level-client 使用 9200 HTTP 协议进行通讯，对常用操作进行语义化封装，相对低阶API 更加友好，但是想要的功能并不一定封装全，任何未实现的功能可通过 低阶API进行操作
 org.elasticsearch.client:elasticsearch-rest-client org.elasticsearch:elasticsearch org.elasticsearch.plugin:parent-join-client org.elasticsearch.plugin:aggs-matrix-stats-client    transport 使用 9300 TCP 协议端口进行通讯，性能好
 transport-netty3-client transport-netty4-client reindex-client  elasticsearch-rest-client       官方建议使用 REST 方式， transport 在 7.0 开始废弃，8.0版本移除
详见官方文档：https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/client.html
  【【注意】】
客户机应该具有与集群相同的版本，起码主版本必须一致
主版本如果不一致，可能会出现调用错误
次版本如果不一致，可能新功能无法使用
 Rest Client &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/plugins/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/plugins/</guid>
      <description>插件机制 ElasticSearch 插件是一个 jar 文件，也可能包含脚本和配置文件，并且必须安装在群集中的每个节点上，安装后，必须重新启动每个节点才能看到插件。
elasticsearch-plugin $ ./bin/elasticsearch-plugin -h A tool for managing installed elasticsearch plugins Commands -------- list - Lists installed elasticsearch plugins install - Install a plugin remove - removes a plugin from Elasticsearch Non-option arguments: command Option Description ------ ----------- -h, --help show help -s, --silent show minimal output -v, --verbose show verbose output elasticsearch-plugin 脚本内容 cat ./bin/elasticsearch-plugin ... declare -a args=(&amp;#34;$@&amp;#34;) path_props=(-Des.path.home=&amp;#34;$ES_HOME&amp;#34;) if [ -e &amp;#34;$CONF_DIR&amp;#34; ]; then path_props=(&amp;#34;${path_props[@]}&amp;#34; -Des.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/profile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/profile/</guid>
      <description>Profile API { ..., &amp;#34;profile&amp;#34; : true, ... } shards.id # ID 格式 [nodeID][indexName][shardID]  GET /_nodes/stats 查看节点信息
 shards.searches shards.searches.query  type 它向我们显示了哪种类型的查询被触发 description 该字段显示启动查询的lucene方法 time lucene 执行此查询所用的时间 breakdown 有关查询的更详细的细节，主要与 lucene 参数有关。 children – 具有多个关键字的查询被拆分成相应术语的布尔查询，每个查询都作为单独的查询来执行。每个子查询的详细信息将填充到Profile API输出的子段中。在上面的章节中，可以看到第一个子元素查询是&amp;quot;levi&amp;rdquo;，下面给出查询时间和其他breakdown参数等详细信息。同样，对于第二个关键字，有一个名为&amp;quot;goals&amp;quot;的子元素具有与其兄弟相同的信息。从查询中的子段中，我们可以得到关于哪个搜索项在总体搜索中造成最大延迟的信息。  shards.searches.rewrite_time 将查询重写成一个或多个组合查询的时间被称为“重写时间”，以纳秒为单位
shards.searches.collector 在 Lucene 中，收集器是负责 收集原始结果，收集组合结果，执行结果排序等的过程。例如，在上面的执行的查询中，当查询语句中给出size:0时，使用的收集器是&amp;quot;totalHitCountCollector&amp;rdquo;。这只返回搜索结果的数量（search_count），不返回文档。此外，收集者所用的时间也一起给出了。
shards.aggregations </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/quick-start-crud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/quick-start-crud/</guid>
      <description>RESTful 增删改查 状态查询 基本信息 $ curl -X GET &amp;#39;http://localhost:9200/&amp;#39; { &amp;#34;name&amp;#34; : &amp;#34;KpRS12p&amp;#34;, &amp;#34;cluster_name&amp;#34; : &amp;#34;elasticsearch&amp;#34;, &amp;#34;cluster_uuid&amp;#34; : &amp;#34;PU5vpob2Q1GyVV-P9o0OwQ&amp;#34;, &amp;#34;version&amp;#34; : { &amp;#34;number&amp;#34; : &amp;#34;5.6.12&amp;#34;, &amp;#34;build_hash&amp;#34; : &amp;#34;cfe3d9f&amp;#34;, &amp;#34;build_date&amp;#34; : &amp;#34;2018-09-10T20:12:43.732Z&amp;#34;, &amp;#34;build_snapshot&amp;#34; : false, &amp;#34;lucene_version&amp;#34; : &amp;#34;6.6.1&amp;#34; }, &amp;#34;tagline&amp;#34; : &amp;#34;You Know, for Search&amp;#34; } 文档个数 $ curl -X GET &amp;#39;http://localhost:9200/_count?pretty&amp;#39; { &amp;#34;count&amp;#34; : 12, &amp;#34;_shards&amp;#34; : { &amp;#34;total&amp;#34; : 6, &amp;#34;successful&amp;#34; : 6, &amp;#34;skipped&amp;#34; : 0, &amp;#34;failed&amp;#34; : 0 } } 集群节点状态 $ curl -X GET &amp;#39;http://localhost:9200/_cluster/state/nodes/?</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/quick-start/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/quick-start/</guid>
      <description>快速开始 Docker 方式安装 安装 # 拉取镜像 $ docker pull elasticsearch # 启动 $ docker run -d -p 9200:9200 -p 9300:9300 \  -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \  -e discovery.type=&amp;#34;single-node&amp;#34; \  --name es elasticsearch # 从 elasticsearch 官方镜像仓库拉取 [速度比较慢] # $ docker pull docker.elastic.co/elasticsearch/elasticsearch:6.6.1 # $ docker run -p 9200:9200 -p 9300:9300 -e &amp;#34;discovery.type=single-node&amp;#34; \ # docker.elastic.co/elasticsearch/elasticsearch:6.6.1   官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html Docker 镜像仓库：https://www.docker.elastic.co/ docker search elasticsearch 搜索镜像   查看基本信息 $ curl http://localhost:9200/ { &amp;#34;name&amp;#34; : &amp;#34;KpRS12p&amp;#34;, &amp;#34;cluster_name&amp;#34; : &amp;#34;elasticsearch&amp;#34;, &amp;#34;cluster_uuid&amp;#34; : &amp;#34;PU5vpob2Q1GyVV-P9o0OwQ&amp;#34;, &amp;#34;version&amp;#34; : { &amp;#34;number&amp;#34; : &amp;#34;5.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Basic/version-history/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Basic/version-history/</guid>
      <description>版本历史  详见官方文档：https://www.elastic.co/cn/downloads/past-releases#elasticsearch
 版本时间概述  0.X  2010-02-08 v0.4.0 2014-03-25 v0.90.13 laster   1.X  2014-02-12 v1.0.0 2015-11-15 v1.7.3 2016-11-15 v1.7.16 laster   2.X  2015-11-28 v2.0.0 2016-08-31 v2.4.0 2017-07-25 v2.4.6 laster    没有 2~3 版本，直接升级到 5  5.X  2016-10-26 v5.0.0 2017-10-11 v5.6.3 ~ using 2018-06-13 v5.6.10 ~ lucene v6.6.1 ~ using 2018-09-18 v5.6.12 ~ lucene v6.6.1 2019-02-19 v5.6.15 laster   6.X  2017-11-14 v6.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Metrics/API_cat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Metrics/API_cat/</guid>
      <description>_cat 接口 _cat 接口的输出格式适合 终端、人眼阅读，不建议应用程序使用
使用方式简单：GET http://localhost:9200/_cat
参数    参数 描述 示例     help 帮助，查看所有的列和描述 /_cat/count?help   v 输出列名    h 指定列表名，多个用 , 分割 ?v&amp;amp;h=* 输出所有列   s 排序，多列用 , 分割 ?s=store.size:desc   bytes 指定单位：b 、k 、m 、g ?v&amp;amp;bytes=b   format text、json、yaml、smile 、cbor    pretty 格式化输出     =^.^=    Type 子接口       Segment /_cat/segments     Segment /_cat/segments/{index}           Doc /_cat/count 文档数    Doc /_cat/count/{index} 文档数          索引 /_cat/indices 索引信息    索引 /_cat/indices/{index} 索引信息    索引 /_cat/aliases 别名    索引 /_cat/aliases/{alias} 别名          分片 /_cat/shards 分片信息    分片 /_cat/shards/{index} 分片信息    分片 /_cat/allocation 分片数、磁盘占用    分片 /_cat/recovery 分片移动恢复情况    分片 /_cat/recovery/{index} 分片移动恢复情况          集群 /_cat/master     集群 ❤ /_cat/nodes ❤性能指标❤ 内存、CPU、负载    集群 /_cat/nodeattrs 节点属性    集群 /_cat/health ❤集群健康❤          线程 /_cat/tasks     线程 /_cat/pending_tasks 挂起等待的任务    线程 /_cat/thread_pool 线程池情况    线程 /_cat/thread_pool/{thread_pools} 线程池情况          Info /_cat/plugins 插件信息    Info /_cat/templates 模板名    Info /_cat/fielddata     Info /_cat/fielddata/{fields}           快照 /_cat/repositories     快照 /_cat/snapshots/{repository}      Read More  cat APIs Elasticsearch Cat 命令  </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Metrics/elasticsearch-metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Metrics/elasticsearch-metrics/</guid>
      <description>elasticsearch-metrics   官方文档：https://grafana.com/grafana/dashboards/878 Github: https://github.com/trevorndodds/elasticsearch-metrics   安装监控脚本 # 下载 Python 文件 $ wget https://raw.githubusercontent.com/trevorndodds/elasticsearch-metrics/master/Grafana/elasticsearch2elastic.py # 编辑 # 修改 ES_METRICS_CLUSTER_URL &amp;amp; ES_METRICS_MONITORING_CLUSTER_URL 为 ES 地址 $ vim elasticsearch2elastic.py # 启动脚本（建议后台运行） $ python elasticsearch2elastic.py 导入 Grafana Dashboard 创建 DataSource  Name：ElasticSearch-Metrics Type：ElasticSearch HTTP  URL：http://x.x.x.x:9200   Elasticsearch details  Pattern：Daily Index name：[elasticsearch_metrics-]YYYY.MM.DD Time field name： @timestamp    导入模板  模板文件：https://grafana.com/api/dashboards/878/revisions/8/download 选择数据源：ElasticSearch-Metrics  大致原理  每 60s（ ES_METRICS_INTERVAL 配置） 调用 ES 原生 API 获取监控数据  /_cluster/health /_cluster/stats /_cat/nodes?</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Metrics/EsRally/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Metrics/EsRally/</guid>
      <description>esrally 压测工具 esrally 是 Elastic 官方开源的一款基于 python3 的针对 ElasticSearch 的压测工具。
官方对 ES 的压测结果  https://elasticsearch-benchmarks.elastic.co/
  环境  CPU: Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz RAM: 32 GB SSD: Crucial MX200 OS: Linux Kernel version 4.8.0-53 JVM: Oracle JDK 1.8.0_131-b11   集群  一台 esrally 一台 ElasticSearch   写入性能  10w+ docs/s   搜索性能  term : 23ms match-all : 123ms range : 543ms scroll : 1,111ms aggs : 3,000ms    esrally 简介 概念  race : 比赛，代表依次基准测 car : 代表 ES 集群 及其 配置 track : rally track 意为 拉力赛道，是针对不同场景的测试数据，压测过程中默认是自动下载的 challenge : 挑战，是基准测试测场景，如：多个客户端每次写多少数据等   总结：在汽车拉力赛(Rally)中，汽车(car)会在赛道(track)开过各种弯道(challenge)完成一次比赛(race)，通过比赛成绩能看出车(手)的能力；通过锦标赛(tournament)可以看出哪个车(手)的水平比较高。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Optimization/Better-Config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Optimization/Better-Config/</guid>
      <description>配置示例 索引模板配置 { /* 模板优先级，数字越大，优先级越高，优先级高的模板覆盖优先级低的模板 */ &amp;#34;order&amp;#34;:0, /* 匹配的索引，如果多个模板匹配一个索引，优先级高的模板覆盖优先级低的模板 */ &amp;#34;template&amp;#34;:&amp;#34;demo-*&amp;#34;, &amp;#34;settings&amp;#34;:{ &amp;#34;index&amp;#34;:{ /* 分片数 */ &amp;#34;number_of_shards&amp;#34;:&amp;#34;3&amp;#34;, /* 副本数 */ &amp;#34;number_of_replicas&amp;#34;:&amp;#34;1&amp;#34;, /* 【可见性】refresh 周期，默认 1s，即数据写入 1s 后可见 */ &amp;#34;refresh_interval&amp;#34;:&amp;#34;60s&amp;#34;, /* 自动生成 doc id 以提高写入效率【7.0废弃】 */ &amp;#34;optimize_auto_generated_id&amp;#34;:&amp;#34;true&amp;#34;, /* 节点脱离集群，主节点延迟重分配分片，以减少重新平衡分片带来的资源浪费，默认 1m */ &amp;#34;unassigned.node_left.delayed_timeout&amp;#34;:&amp;#34;1d&amp;#34;, /* flush 策略 */ &amp;#34;translog&amp;#34;:{ /* 【可靠性】异步刷新，存在数据丢失的情况，默认 request， */ &amp;#34;durability&amp;#34;:&amp;#34;async&amp;#34;, /* 【可靠性】异步刷新间隔 */ &amp;#34;sync_interval&amp;#34;:&amp;#34;30s&amp;#34;, /* 允许 translog 在 flush 前存放更大的 Segment，以减少 flush 的频率，减少磁盘IO */ &amp;#34;flush_threshold_size&amp;#34;:&amp;#34;1000mb&amp;#34; }, &amp;#34;merge&amp;#34;:{ &amp;#34;policy&amp;#34;:{ /* 默认 5G */ &amp;#34;max_merged_segment&amp;#34;:&amp;#34;2gb&amp;#34;, /* 分段的数量，数值越小，最终 segment 越少，但是需要 merge 的操作会更多，默认 10 */ &amp;#34;segments_per_tier&amp;#34;:&amp;#34;24&amp;#34;, /* 默认一次合并的分段数 */ &amp;#34;max_merge_at_once&amp;#34;: &amp;#34;10&amp;#34; }, &amp;#34;scheduler&amp;#34;:{ /* Merge 线程数，默认 max(1, min(4, cpu/2))， 机械硬盘建议1，SSD 可调高 */ &amp;#34;max_thread_count&amp;#34;:&amp;#34;1&amp;#34; } } } }, &amp;#34;mappings&amp;#34;:{ &amp;#34;doc&amp;#34;:{ &amp;#34;_all&amp;#34;:{ /* _all 字段包含所有字段分析后的信息，作用是在搜索时不指定特定的字段 */ /* ES6 之后，默认禁用，可明显降低 CPU 和 IO 压力 */ &amp;#34;enabled&amp;#34;:false }, &amp;#34;_source&amp;#34; : { /* 用于存储 doc 原始数据，对于不需要存储的字段可禁用 */ &amp;#34;enabled&amp;#34; : false, /* 包含指定的字段 */ &amp;#34;includes&amp;#34;:[&amp;#34;field1&amp;#34;,&amp;#34;field2&amp;#34;], /* 排除指定的字段 */ &amp;#34;excludes&amp;#34;:[&amp;#34;field1&amp;#34;,&amp;#34;field2&amp;#34;] } } } } elasticsearch.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Optimization/Better-Search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Optimization/Better-Search/</guid>
      <description>搜索性能优化 硬件/系统  为系统 cache 预留 至少一半的可用物理内存  搜索依赖对系统的 cache 的命中   禁用 swap  swap 分区是从磁盘空间划分而来   更快的硬件  写入性能对 CPU 更敏感 搜索性能更在意 IO 能力  搜索请求有更多的所及访问 使用 SSD 比 旋转介质 还有质的飞跃 如果搜索类型计算比较多，考虑使用更快的 CPU      查看 swap # 或 free -m $ swapon -s Filename Type Size Used Priority /dev/dm-1 partition 2097144 0 -1 关闭 swap $ swapoff /dev/dm-1 索引/建模  合理建模  嵌套 会使查询慢 几倍 ？？？ 父子 会使查询慢 百倍 ？？？   预索引数据  搜索时需要 范围查询 range 的字段，在生成索引时进行计算，生成新的字段，变为 terms 查询   字段映射  keyword 比 integer 和 long 更好   为只读索引执行 forceMerge、Shrink  基于日期进行轮训的索引，旧数据一般不会更新   预热全局序号（Global Ordinals）？？？ 【6.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/ElasticSearch/docs/Optimization/Better-Write/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/ElasticSearch/docs/Optimization/Better-Write/</guid>
      <description>写入性能优化 整体思路  牺牲可靠性 和 搜索实时性 增加 refresh 间隔，减小搜索实时性 增加 flush 间隔，降低 segment merge 频率 增加 bulk 请求  时效性 refresh_interval  index.refresh_interval  默认 1s，即数据写入 1s 后可被搜索到    translog flush  默认 每个请求都 flush 相关配置  index.translog.durability  request async  index.translog.sync_interval: 默认 5s   index.translog.flush_threshold_size: 默认 512m      段合并  ES 2.0 开始，merge 行为不再由 ES 控制，而是由 Lucene 控制 index.merge.scheduler.max_thread_count  默认： max(1, min(4, cpu/2)) 机械硬盘建议：1   index.</description>
    </item>
    
  </channel>
</rss>